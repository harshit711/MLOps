# Crypto ETL Pipeline using Apache Airflow

## Overview

This project demonstrates a data engineering workflow using **Apache Airflow** to automate the **Extract, Transform, Load, and Analyze (ETL)** process for cryptocurrency data.

The workflow reads raw cryptocurrency data, performs data cleaning and transformation, loads the processed dataset into a clean file, and computes analytical metrics such as average price per cryptocurrency symbol.

**Apache Airflow**: Airflow is an open-source platform for programmatically authoring, scheduling, and monitoring workflows.

The workflow involves the following steps:
1. Extract raw cryptocurrency data from a local CSV file.
2. Transform and normalize the price fields.
3. Load the cleaned data into an output CSV file.
4. Analyze and compute the average price per symbol.

---

## Setting up the Lab
